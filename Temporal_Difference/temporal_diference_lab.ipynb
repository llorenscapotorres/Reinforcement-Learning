{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c12d880a",
   "metadata": {},
   "source": [
    "# Windy Gridworld\n",
    "\n",
    "Imagine a standard gridworld, with start and goal states, but with one difference: there is a crosswind running upward through the middle of the grid. The actions are the standard four -`up`, `down`, `right`, `left`- but in the middle region the resultant next states are shifted upward by \"wind\", the strength of which varies from column to column.\n",
    "\n",
    "This is an undiscounted episodic task, with **constant rewards of -1** until the goal is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc52f42",
   "metadata": {},
   "source": [
    "## Windy Gridworld Static Wind\n",
    "\n",
    "Let's say the first 3 columns don't have wind, the next 3 columns have wind by 1, then the next 2 columns have wind by 2, then 1 and finally 0. So, we have a griworld of 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c029c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TD_methods import td_sarsa_control\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40884e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create just the gridworld\n",
    "gridworld = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 0, 0] # This row represents the wind in each column\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a692de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = gridworld.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25444f2c",
   "metadata": {},
   "source": [
    "Say that a state is represented by a tuple, which has the position in the first index, and the wind in the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba207d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_terminal_states=[]\n",
    "terminal_states=[]\n",
    "initial_states=[]\n",
    "for i in range(n-1):\n",
    "    for j in range(m):\n",
    "        if gridworld[i, j] != 0:\n",
    "            if gridworld[i, j] == 1:\n",
    "                non_terminal_states.append(((i, j), gridworld[n-1, j]))\n",
    "            elif gridworld[i, j] == 2:\n",
    "                initial_states.append(((i, j), gridworld[n-1, j]))\n",
    "                non_terminal_states.append(((i, j), gridworld[n-1, j]))\n",
    "            else:\n",
    "                terminal_states.append(((i, j), gridworld[n-1, j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80390db",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions={}\n",
    "states = non_terminal_states + terminal_states\n",
    "for state in states:\n",
    "    actions[state] = [action for action in ['up', 'down', 'right', 'left']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cefc830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_step_static_wind(state, action):\n",
    "    \"\"\"\n",
    "    Takes as input a state and an action, and returns a (state, reward) tuple that follows the state-action pair.\n",
    "    \"\"\"\n",
    "    def invalid_position(position: tuple):\n",
    "        if gridworld[position] == 0:\n",
    "            return True\n",
    "    i, j = state[0]\n",
    "    wind = state[1]\n",
    "\n",
    "    if action == 'up':\n",
    "        new_position = (i + 1 + wind, j)\n",
    "    elif action == 'down':\n",
    "        new_position = (i - 1 + wind, j)\n",
    "    elif action == 'right':\n",
    "        new_position = (i + wind, j + 1)\n",
    "    else:\n",
    "        new_position = (i + wind, j - 1)\n",
    "    \n",
    "    if invalid_position(new_position):\n",
    "        return (state, -1)\n",
    "    # The next state depends on thw wind, and wind depends on the 'j'\n",
    "    new_wind = gridworld[n-1, new_position[1]]\n",
    "    return (((new_position), new_wind), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6639e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Q, policy = \u001b[43mtd_sarsa_control\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_terminal_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_terminal_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mterminal_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mterminal_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                 \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mnext_step_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_step_static_wind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                 \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                 \u001b[49m\u001b[43minitial_Q\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Usuario\\Documents\\Reinforcement-Learning\\Temporal_Difference\\TD_methods.py:132\u001b[39m, in \u001b[36mtd_sarsa_control\u001b[39m\u001b[34m(non_terminal_states, terminal_states, initial_states, actions, next_step_fn, gamma, alpha, epsilon, num_episodes, initial_Q)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epsilon_was_none:\n\u001b[32m    131\u001b[39m     epsilon = \u001b[32m1\u001b[39m/t\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m next_state, reward = \u001b[43mnext_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# Choose the next action from the state\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.random.random() > epsilon:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36mnext_step_static_wind\u001b[39m\u001b[34m(state, action)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnext_step_static_wind\u001b[39m(state, action):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Takes as input a state and an action, and returns a (state, reward) tuple that follows the state-action pair.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_position\u001b[39m(position: \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "Q, policy = td_sarsa_control(non_terminal_states=non_terminal_states,\n",
    "                 terminal_states=terminal_states,\n",
    "                 initial_states=initial_states,\n",
    "                 actions=actions,\n",
    "                 next_step_fn=next_step_static_wind,\n",
    "                 gamma=1.0,\n",
    "                 alpha=0.5,\n",
    "                 epsilon=0.1,\n",
    "                 num_episodes=100000,\n",
    "                 initial_Q=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "820ee3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = initial_states[0]\n",
    "policy[initial_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "848b95bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1), np.int64(0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb138ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((5, np.int64(1)), np.int64(0)), -1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_step_static_wind(initial_state, policy[initial_state])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
